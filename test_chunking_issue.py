#!/usr/bin/env python3
"""
Test script to demonstrate the chunking issue where spaces are lost
"""

def split_text_into_chunks_broken(text, max_chunk_size=100):
    """Original broken chunking function"""
    words = text.split()
    chunks = []
    current_chunk = ""
    
    for word in words:
        if len(current_chunk + " " + word) <= max_chunk_size:
            current_chunk += (" " + word) if current_chunk else word
        else:
            if current_chunk:
                chunks.append(current_chunk)
            current_chunk = word
    
    if current_chunk:
        chunks.append(current_chunk)
    
    return chunks

def split_text_into_chunks_fixed(text, max_chunk_size=100):
    """Fixed chunking function that preserves original spacing"""
    chunks = []
    current_chunk = ""
    current_length = 0
    
    # Split by words but preserve the original spacing
    import re
    # Split by word boundaries but keep the separators
    parts = re.split(r'(\s+)', text)
    
    for part in parts:
        # If adding this part would exceed the limit
        if current_length + len(part) > max_chunk_size and current_chunk:
            # Save current chunk and start new one
            chunks.append(current_chunk)
            current_chunk = part
            current_length = len(part)
        else:
            # Add to current chunk
            current_chunk += part
            current_length += len(part)
    
    # Add the last chunk if it exists
    if current_chunk:
        chunks.append(current_chunk)
    
    return chunks

def test_chunking():
    """Test both chunking methods"""
    # Test text with various spacing
    test_text = "ĞĞ°Ñ‡Ğ¸Ğ½Ğ°Ğ»Ğ¾ Ñ‚ĞµĞ¼Ğ½ĞµÑ‚ÑŒ, ĞºĞ¾Ğ³Ğ´Ğ° Ğ±Ñ€Ğ¸Ğ³Ğ°Ğ´Ğ¸Ñ€ ÑĞºĞ°Ğ·Ğ°Ğ» Ğ² Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ Ñ€Ğ°Ğ·:\n     - ĞœĞ¾Ğµ Ğ¾ĞºĞ¾Ğ½Ñ‡Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑĞ»Ğ¾Ğ²Ğ¾ - Ñ‚Ñ‹ÑÑÑ‡Ğ° ÑˆĞµÑÑ‚ÑŒÑĞ¾Ñ‚. ĞŸÑ€Ğ¸Ñ‡ĞµĞ¼ ÑĞµĞ¹Ñ‡Ğ°Ñ, Ğ²Ğ¾Ñ‚ Ğ·Ğ´ĞµÑÑŒ, Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸... Ğ"
    
    print("ğŸ” TESTING CHUNKING METHODS")
    print("=" * 60)
    print(f"ğŸ“„ Original text: '{test_text}'")
    print(f"ğŸ“Š Original length: {len(test_text)} characters")
    print()
    
    # Test broken method
    print("âŒ BROKEN METHOD (word-based):")
    broken_chunks = split_text_into_chunks_broken(test_text, 50)
    print(f"ğŸ“¦ Chunks created: {len(broken_chunks)}")
    for i, chunk in enumerate(broken_chunks):
        print(f"   Chunk {i+1}: '{chunk}' ({len(chunk)} chars)")
    
    broken_total = sum(len(chunk) for chunk in broken_chunks)
    print(f"ğŸ“Š Total in chunks: {broken_total} characters")
    print(f"ğŸ“Š Characters lost: {len(test_text) - broken_total}")
    print()
    
    # Test fixed method
    print("âœ… FIXED METHOD (preserves words AND spacing):")
    fixed_chunks = split_text_into_chunks_fixed(test_text, 50)
    print(f"ğŸ“¦ Chunks created: {len(fixed_chunks)}")
    for i, chunk in enumerate(fixed_chunks):
        print(f"   Chunk {i+1}: '{chunk}' ({len(chunk)} chars)")
    
    fixed_total = sum(len(chunk) for chunk in fixed_chunks)
    print(f"ğŸ“Š Total in chunks: {fixed_total} characters")
    print(f"ğŸ“Š Characters lost: {len(test_text) - fixed_total}")
    print()
    
    # Verify reconstruction
    print("ğŸ” RECONSTRUCTION TEST:")
    broken_reconstructed = "".join(broken_chunks)
    fixed_reconstructed = "".join(fixed_chunks)
    
    print(f"âŒ Broken method reconstruction: '{broken_reconstructed}'")
    print(f"âœ… Fixed method reconstruction: '{fixed_reconstructed}'")
    print(f"ğŸ“„ Original text: '{test_text}'")
    print()
    
    print(f"âŒ Broken matches original: {broken_reconstructed == test_text}")
    print(f"âœ… Fixed matches original: {fixed_reconstructed == test_text}")
    
    # Show what was lost in broken method
    if broken_reconstructed != test_text:
        print("\nğŸ” WHAT WAS LOST IN BROKEN METHOD:")
        print("Original spacing and formatting:")
        print(repr(test_text))
        print("Broken reconstruction:")
        print(repr(broken_reconstructed))

if __name__ == "__main__":
    test_chunking() 
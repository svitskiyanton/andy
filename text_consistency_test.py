#!/usr/bin/env python3
"""
Text Consistency Test - Test version that simulates text streaming without ElevenLabs
Shows input/output text consistency and buffering behavior
"""

import asyncio
import time
import os
from dotenv import load_dotenv

# Import the progressive streaming class
from progressive_streaming_test import ProgressiveWebSocketStreamingTest

# Load environment variables
load_dotenv()

class TextConsistencyTest:
    def __init__(self, text_file_path="large_text.txt"):
        self.text_file_path = text_file_path
        self.chunk_size = 100  # Characters per chunk
        self.delay_between_chunks = 0.1  # Seconds between chunks
        
        # Test metrics
        self.total_chunks = 0
        self.processed_chunks = 0
        self.start_time = None
        
        # Text tracking
        self.input_text = ""
        self.output_text = ""
        self.chunk_history = []
        
        # Check if text file exists
        if not os.path.exists(self.text_file_path):
            self._create_sample_text_file()
    
    def _create_sample_text_file(self):
        """Create a sample large text file if it doesn't exist"""
        sample_text = """
–¢–∞–∫ –ø–æ—á–µ–º—É –∂–µ –≤—ã –∑–¥–µ—Å—å?
     - –ê –≥–¥–µ –∂–µ –º–Ω–µ –±—ã—Ç—å? –ì–¥–µ –∂–µ –º–Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å, –ø–æ-—Ç–≤–æ–µ–º—É? –í —à–∫–æ–ª–µ? –ß—Ç–æ —è —Ç–∞–º
–±—É–¥—É –≤–æ—Ä–æ–≤–∞—Ç—å, –ø—Ä–æ–º–æ–∫–∞—à–∫–∏?!  –£—Å—Ç—Ä–∞–∏–≤–∞—è—Å—å –Ω–∞ —Ä–∞–±–æ—Ç—É, —Ç—ã  –¥–æ–ª–∂–µ–Ω  –ø—Ä–µ–∂–¥–µ –≤—Å–µ–≥–æ
–∑–∞–¥—É–º–∞—Ç—å—Å—è: —á—Ç–æ, –≥–¥–µ –∏ –∫–∞–∫? –ß—Ç–æ —è —Å–º–æ–≥—É —É–∫—Ä–∞—Å—Ç—å? –ì–¥–µ  —è —Å–º–æ–≥—É —É–∫—Ä–∞—Å—Ç—å? –ò –∫–∞–∫
—è  —Å–º–æ–≥—É —É–∫—Ä–∞—Å—Ç—å?.. –¢—ã  –ø–æ–Ω—è–ª?  –í–æ—Ç –∏ —Ö–æ—Ä–æ—à–æ. –í—Å–µ –±—É–¥–µ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ.  –ö –≤–µ—á–µ—Ä—É
–±–∞–±–∫–∏ –ø–æ—è–≤—è—Ç—Å—è.

–≠—Ç–æ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –±–æ–ª—å—à–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ—Ç–æ–∫–æ–≤–æ–π –ø–µ—Ä–µ–¥–∞—á–∏. –ú—ã –±—É–¥–µ–º
–æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç –Ω–µ–±–æ–ª—å—à–∏–º–∏ —á–∞—Å—Ç—è–º–∏, —á—Ç–æ–±—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞—à–∞
—Å–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–≥–æ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞. –ö–∞–∂–¥–∞—è —á–∞—Å—Ç—å –±—É–¥–µ—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ,
—á—Ç–æ –ø–æ–∑–≤–æ–ª–∏—Ç –Ω–∞–º –ø–æ–ª—É—á–∏—Ç—å –ø–ª–∞–≤–Ω–æ–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –∞—É–¥–∏–æ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.

–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –µ—â–µ –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ç–µ–∫—Å—Ç–∞. –≠—Ç–æ –ø–æ–º–æ–∂–µ—Ç –Ω–∞–º
—É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Å–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ –¥–∞–∂–µ —Å –¥–ª–∏–Ω–Ω—ã–º–∏ —Ç–µ–∫—Å—Ç–∞–º–∏. –ú—ã —Ç–∞–∫–∂–µ
–ø—Ä–æ–≤–µ—Ä–∏–º, –∫–∞–∫ —Å–∏—Å—Ç–µ–º–∞ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏.

–ï—â–µ –±–æ–ª—å—à–µ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è. –≠—Ç–æ—Ç —Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã,
—Ü–∏—Ñ—Ä—ã 123, –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã: !@#$%^&*(). –ú—ã —Ö–æ—Ç–∏–º —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –Ω–∞—à–∞
—Å–∏—Å—Ç–µ–º–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ —Ç–∏–ø—ã —Å–∏–º–≤–æ–ª–æ–≤ –∏ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è.

–§–∏–Ω–∞–ª—å–Ω–∞—è —á–∞—Å—Ç—å –Ω–∞—à–µ–≥–æ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ç–µ–∫—Å—Ç–∞. –ö —ç—Ç–æ–º—É –º–æ–º–µ–Ω—Ç—É –º—ã –¥–æ–ª–∂–Ω—ã –±—ã–ª–∏
–æ—Ç–ø—Ä–∞–≤–∏—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–µ–∫—Å—Ç–∞, —á—Ç–æ–±—ã –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –≤—Å—é —Å–∏—Å—Ç–µ–º—É –ø–æ—Ç–æ–∫–æ–≤–æ–π
–ø–µ—Ä–µ–¥–∞—á–∏. –ù–∞–¥–µ–µ–º—Å—è, —á—Ç–æ –∞—É–¥–∏–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –ø–ª–∞–≤–Ω–æ –∏ –±–µ–∑ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–π.
        """
        
        with open(self.text_file_path, 'w', encoding='utf-8') as f:
            f.write(sample_text.strip())
        
        print(f"üìù Created sample text file: {self.text_file_path}")
    
    def _read_text_file(self):
        """Read the text file and return its content"""
        try:
            with open(self.text_file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            return content.strip()
        except Exception as e:
            print(f"‚ùå Error reading text file: {e}")
            return None
    
    def _split_text_into_chunks(self, text):
        """Split text into chunks for streaming (same logic as original)"""
        chunks = []
        current_chunk = ""
        words = text.split()
        
        for word in words:
            if len(current_chunk + " " + word) <= self.chunk_size:
                current_chunk += (" " + word) if current_chunk else word
            else:
                if current_chunk:
                    chunks.append(current_chunk)
                current_chunk = word
        
        if current_chunk:
            chunks.append(current_chunk)
        
        return chunks
    
    def _split_text_into_chunks_preserve_whitespace(self, text):
        """Split text into chunks while preserving whitespace"""
        chunks = []
        current_chunk = ""
        
        # Split by words but preserve original spacing
        import re
        parts = re.split(r'(\s+)', text)
        
        for part in parts:
            if len(current_chunk + part) <= self.chunk_size:
                current_chunk += part
            else:
                if current_chunk.strip():  # Only add non-empty chunks
                    chunks.append(current_chunk)
                current_chunk = part
        
        if current_chunk.strip():
            chunks.append(current_chunk)
        
        return chunks
    
    def _show_progress(self, current, total, chunk_text):
        """Show streaming progress in console"""
        progress = (current / total) * 100
        bar_length = 30
        filled_length = int(bar_length * current // total)
        bar = '‚ñà' * filled_length + '‚ñë' * (bar_length - filled_length)
        
        print(f"\rüì§ [{bar}] {progress:.1f}% ({current}/{total}) | '{chunk_text[:30]}...'", end='', flush=True)
    
    async def test_text_consistency(self):
        """Test text consistency without sending to ElevenLabs"""
        # Read text file
        text_content = self._read_text_file()
        if not text_content:
            return
        
        # Store original input text
        self.input_text = text_content
        
        # Split into chunks (preserving whitespace)
        text_chunks = self._split_text_into_chunks_preserve_whitespace(text_content)
        self.total_chunks = len(text_chunks)
        
        print("üß™ Starting Text Consistency Test...")
        print("=" * 80)
        print(f"üìÅ Text file: {self.text_file_path}")
        print(f"üìä Total text length: {len(text_content):,} characters")
        print(f"üì¶ Total chunks: {self.total_chunks}")
        print(f"‚è±Ô∏è  Simulated time: {self.total_chunks * self.delay_between_chunks:.1f} seconds")
        print("=" * 80)
        
        # Simulate the text streaming process
        print("\nüì§ Simulating text chunk streaming...")
        self.start_time = time.time()
        
        # Process each chunk (simulate what the original system does)
        for i, chunk in enumerate(text_chunks):
            # Store chunk history
            self.chunk_history.append({
                'index': i + 1,
                'chunk': chunk,
                'length': len(chunk),
                'timestamp': time.time() - self.start_time
            })
            
            # Show progress
            self._show_progress(i + 1, self.total_chunks, chunk)
            
            # Simulate processing delay
            await asyncio.sleep(self.delay_between_chunks)
        
        # Reconstruct output text from chunks (preserve original spacing)
        self.output_text = "".join([chunk['chunk'] for chunk in self.chunk_history])
        
        # Calculate final metrics
        total_time = time.time() - self.start_time
        
        print("\n" + "=" * 80)
        print("üß™ TEXT CONSISTENCY TEST RESULTS:")
        print("=" * 80)
        
        # Input vs Output comparison
        print("üìä TEXT COMPARISON:")
        print(f"Input text length:  {len(self.input_text):,} characters")
        print(f"Output text length: {len(self.output_text):,} characters")
        print(f"Text match: {'‚úÖ YES' if self.input_text == self.output_text else '‚ùå NO'}")
        
        if self.input_text != self.output_text:
            print("\n‚ö†Ô∏è  TEXT DIFFERENCES DETECTED:")
            print("Input text:")
            print(f"'{self.input_text[:100]}...'")
            print("\nOutput text:")
            print(f"'{self.output_text[:100]}...'")
        
        # Chunk analysis
        print(f"\nüì¶ CHUNK ANALYSIS:")
        print(f"Total chunks processed: {len(self.chunk_history)}")
        print(f"Average chunk size: {sum(chunk['length'] for chunk in self.chunk_history) / len(self.chunk_history):.1f} characters")
        print(f"Largest chunk: {max(chunk['length'] for chunk in self.chunk_history)} characters")
        print(f"Smallest chunk: {min(chunk['length'] for chunk in self.chunk_history)} characters")
        
        # Timing analysis
        print(f"\n‚è±Ô∏è  TIMING ANALYSIS:")
        print(f"Total processing time: {total_time:.2f} seconds")
        print(f"Average time per chunk: {total_time / len(self.chunk_history):.3f} seconds")
        print(f"Processing rate: {len(self.chunk_history) / total_time:.1f} chunks/second")
        
        # Show first few chunks
        print(f"\nüìã FIRST 5 CHUNKS:")
        for i, chunk_info in enumerate(self.chunk_history[:5]):
            print(f"Chunk {chunk_info['index']}: '{chunk_info['chunk'][:50]}...' ({chunk_info['length']} chars)")
        
        # Show last few chunks
        if len(self.chunk_history) > 5:
            print(f"\nüìã LAST 5 CHUNKS:")
            for chunk_info in self.chunk_history[-5:]:
                print(f"Chunk {chunk_info['index']}: '{chunk_info['chunk'][:50]}...' ({chunk_info['length']} chars)")
        
        print("=" * 80)
        
        # Final verdict
        if self.input_text == self.output_text:
            print("‚úÖ CONSISTENCY TEST PASSED: Input and output text match perfectly!")
        else:
            print("‚ùå CONSISTENCY TEST FAILED: Input and output text do not match!")
        
        return self.input_text == self.output_text

async def main():
    """Main function"""
    # You can specify a different text file path here
    text_file = "large_text.txt"  # Change this to your text file
    
    tester = TextConsistencyTest(text_file)
    success = await tester.test_text_consistency()
    
    if success:
        print("\nüéâ Text streaming consistency verified! Your system is ready for ElevenLabs.")
    else:
        print("\n‚ö†Ô∏è  Text streaming consistency issues detected. Check the chunking logic.")

if __name__ == "__main__":
    asyncio.run(main()) 